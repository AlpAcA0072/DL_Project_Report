% !Mode:: "TeX:UTF-8"
% !TEX program  = xelatex
\section{Related Work}
This chapter is based on the requirements of realizing image segmentation on the mobile terminal, I studied the classical FCN \cite{long2015fully} semantic segmentation algorithm and the FPN-based FaPN \cite{huang2021fapn} algorithm, analyze the problems running on the mobile terminal and choose to improve the FaPN model.


\subsection{Feature Pyramid Networks}
Feature Pyramid Networks \cite{lin2017feature} is an article published in CVPR by Tsung-Yi Lin et al. in 2017. It integrates the semantic information of the bottom layer and the upper layer by adding a feature pyramid module to the Dense prediction problem and improves the accuracy of target detection, especially for the detection of small objects.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.3\linewidth}
        \includegraphics[width=1\textwidth]{figures/fcnarch1.png}
        \caption{Featurized Image Pyramid}\label{FCNarch1}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\linewidth}
        \includegraphics[width=1\textwidth]{figures/fcnarch2.png}
        \caption{Pyramid Feature Hierarchy}\label{FCNarch2}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\linewidth}
        \includegraphics[width=1\textwidth]{figures/fcnarch3.png}
        \caption{Single Feature Map}\label{FCNarch3}
    \end{subfigure}
    \caption{Typical methods applied on segmentation tasks}\label{FCNarch}
\end{figure}


There are three typical structures applied on segmentation tasks: a) Featurized image pyramid, b) Pyramid feature hierarchy, and c) Single feature map. Among them, the Featurized image pyramid obtains the features of different scales through images of different resolutions and makes separate predictions for the features of each scale. The problem is that the time cost is too high. The pyramid feature hierarchy extracts different levels of semantic information from images through the network and predicts them separately. In this way, when high-level semantic information is used, the detection effect of small objects is not good. A single feature map only predicts the feature map of the highest layer of the network, but the resolution of the feature map of the highest layer is low, and the prediction of the position of the object is not accurate enough.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{figures/FPN_h.png}
    \caption{FPN's Structure \cite{plotNeuralNet}}\label{FPN}
\end{figure}

The FPN network uses the top-down pathway to combine the feature information of the bottom layer and the upper layer resolution. By upsampling, the more abstract high-level feature map and laterally connecting it with the lower-level feature map, the feature information of the high-level layer is strengthened. In this way, the feature information of the upper layer and the position information of the bottom layer is used at the same time, thereby improving the accuracy of dense prediction, especially for the prediction of small objects.


\subsection{Feature-aligned Pyramid Networks}

Based on FPN, Shihua Huang further proposed Feature-aligned Pyramid Networks \cite{huang2021fapn}. FPN and most of the existing networks do not consider the problem of feature alignment, which leads to the upsampling of high-level semantics, and the upsampled local features are directly filled with pixels by interpolation methods. The interpolated pixel padding can lead to misalignment of the upper and lower layer features of small objects and object boundaries, which in turn leads to misclassification in prediction.

For the above problems, the author proposes FAM (Feature Alignment Module) and FSM (Feature Selection Module) to help the model obtain more accurate upper-level semantic location information.

%两个模块解释（伪代码放在实现部分）：

%因为在上卷积层向下卷积层进行上采样的过程中存在特征无法对齐的问题，所以在上采样的过程中，作者通过添加的FAM模块对这些特征样本进行了对齐。具体过程如下
Because of the problem that the features cannot be aligned in the process of upsampling the upper convolutional layer and the down convolutional layer, the author aligns these feature samples through the added FAM module during the upsampling process. The specific process is as follows:

For a given upsampled feature map $P_i$, the spatial misalignment between it and the bottom-up feature map $C_i$ is predictable.


Unaligned upsampled layers' features and bottom-up feature maps' features may lead to the wrong prediction of upsampled layers' features in the process of recursive upsampling, which in turn leads to the wrong prediction of small objects and object edges, so the alignment of features in upsampled layers' $P_i$ and bottom-up feature maps' features $C_i$ is very necessary. The spatial location information, the offset $\Delta_i$ is provided by both the feature's location in $C_i$ and $P_i$. With the information provided, the aligned feature could be calculated according to the offset $\Delta_i$ and unaligned feature $P^u_i$ in upsampled layer $P_i$. The mathematical formulation is present as in Equation (\ref{con:FAM}) \cite{huang2021fapn}

\begin{equation}
    \begin{aligned}
        \Delta_i = f_a([\hat{\textbf{C}}_{i-1}, \textbf{P}^u_i]),\\
    \hat{\textbf{P}}^u_i = f_m(\textbf{P}^u_i, \Delta_i),
    \label{con:FAM}
    \end{aligned}
\end{equation}

where $\Delta_i$ denotes the offset distance from the unaligned feature $C_i$ to the $P^u_i$, in which the $\hat{C}_{i-1}$ denotes the reference of $C_i$. $f_b(·)$ denotes the calculation procedure of the aligned feature $\hat{P}^u_i$. The algorithm is implemented by the deformable convolutions \cite{dai2017deformable}.


In the typical FPN, the bottom-up feature maps are added with the upsampled feature maps after a 1 * 1 convolutional layer. Thus, it's necessary to selectively use the useful feature. The mathematical formulation is present as in Equation(\ref{con:FSM}) \cite{huang2021fapn}

\begin{equation}
    \begin{aligned}
    \textbf{u} = f_m(\textbf{z}),\\
    \hat{\textbf{C}}_i = f_s(\textbf{C}_i+\textbf{u}*\textbf{C}_i),
    \label{con:FSM}
    \end{aligned}
\end{equation}

where the \textbf{u} indicates the importance vector, for each feature map there's an importance value to add all up. The importance value is extracted according to Equation(\ref{con:AVEPOOL}) \cite{huang2021fapn}

\begin{equation}
    \begin{aligned}
    \textbf{z}= [z_1, z_2, ..., z_D],\\
    \textbf{z}_d = \frac{1}{H_i * W_i}\sum_{h = 1}^{H_i}\sum_{w = 1}^{W_i}c_d(h,w),
    \label{con:AVEPOOL}
    \end{aligned}
\end{equation}

%这个平均池化的操作保证了对于feature map的重要特征的提取和提取后的一致性。使重要的特征得到了增强，不重要的特征被减弱。
This average pooling operation ensures the extraction and consistency of the important features of the feature map after extraction. The important features are enhanced, and the unimportant features are weakened.

% \subsection{Paddle Lite}
% Paddle Lite \cite{paddlelite} is an end-to-end reasoning engine launched by Paddle Mobile based on the new upgrade of Paddle Mobile. It is more complete in the support of multi-hardware, multi-platform and hardware hybrid scheduling, and provides efficient and lightweight AI applications for end-side scenarios including mobile phones. Reasoning ability, effectively solve problems such as mobile phone computing power and memory limitations, and are committed to promoting the wider implementation of AI applications.

\clearpage